import os.path
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import tree
from sklearn.inspection import DecisionBoundaryDisplay
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.feature_extraction.text import CountVectorizer
import random

vocab_list = [
    "iex",
    "invoke",
    "expression",
    "webclient",
    "getstring",
    "assembly",
    "object",
    "if",
    "else",
    "net",
]

vectorizerizer = CountVectorizer(vocabulary=vocab_list,
                                     lowercase=True,
                                     decode_error='ignore',
                                     token_pattern=r"(?u)\b\w[\w\.]+\b")

documents = []
malware_folders = ["samples_benign", "samples_malicious", "D:\\Malware\\PowerShell_malicious", "D:\\Malware\\PowerShell_benign"]

features_list = []
for folderPath in malware_folders:
    fileList = os.listdir(folderPath)
    random.shuffle(fileList)
    for file in fileList:
        full_path = os.path.join(folderPath, file)
        #print(f"Analyzing: {full_path}")
        try:
            code = open(full_path).read()
        except Exception as e:
            if "utf-16-le" in str(e):
                code = open(full_path, encoding='utf-16').read()
            else:
                print(f"Unknown encoding for: {full_path} . Will attempt to read it anyway")
                try:
                    code = open(full_path, errors='ignore').read()
                except Exception as f:
                    print(f"Failed to load: {full_path} Error: {str(f)}")
                    continue

        # Initilize the feature list
        dict_features = {}
        for word in vocab_list:
            dict_features[word] = 0
            if word in code.lower():
                dict_features[word] = 1
        if 'benign' in full_path.lower():
            dict_features['class'] = 'benign'
        else:
            dict_features['class'] = 'malware'
        features_list.append(dict_features)


df_full = pd.DataFrame(features_list)

#word_count_matrix = vectorizerizer.fit_transform(documents)
#word_count_array = word_count_matrix.toarray()
#feature_names = vectorizerizer.get_feature_names_out()

#df_full = pd.DataFrame(word_count_matrix, columns=feature_names)

X = df_full.values[:, : -1]
Y = df_full.values[:, -1]
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=100)

le = preprocessing.LabelEncoder()
df_full_plus = df_full.apply(le.fit_transform)

tree_gini = DecisionTreeClassifier(criterion = "entropy", random_state = 50, max_depth=3) # min_samples_leaf=5
tree_gini.fit(X_train, y_train)
plt.figure(figsize=(20,15))
featureNames =  list(df_full.columns[:-1])
classNamesList =  list(df_full.values[:,-1])
tree.plot_tree(tree_gini, feature_names= featureNames, class_names=['benign','malicious'], filled=True ,proportion = False, impurity=False, label='none', fontsize=14, max_depth=15) # class_names=classNamesList
plt.show()

#df_full = pd.read_csv('Firewall_Rule_Classification.csv')
#print("Data Loaded")

